{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de un SAE sobre las salidad y activaciones de la MLP intermedia de llama3.2 1B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Costo de entrenamiento\n",
    "\n",
    "Generalmente, el costo computacional de un LLM está dominado por la evaluación\n",
    "de sus MLPs (referencia a el seminario en una universidad de un ex empleado\n",
    "de anthropic)\n",
    "\n",
    "Una aprocimación simple del costo de entrenamiento de un modelo es\n",
    "\n",
    "$$\n",
    "  6ND \n",
    "$$\n",
    "esto en términos de FLOPs (operaciones de punto flotante).\n",
    "(citar a chinchilla scaling laws)\n",
    "\n",
    "donde $N$ es el número de parámetros y $D$ la cantidad de muestras en el\n",
    "conjunto de entrenamiento.\n",
    "\n",
    "Esto se debe a que, generalmente, cada parámetro actua en una multiplicaciónl\n",
    "y en una suma de punto flotante, dandonos un costo de $2ND$ tan solo en el\n",
    "forward pass. Tipicamente, el costo de el backward pass es el doble del forward\n",
    "pass, haciendo que su costo sea $4ND$. Sumando tenemos el resultado previamente\n",
    "mencionado.\n",
    "\n",
    "Sea $N_l$ el número de parámetros de llama.\n",
    "Como nosotros vamos a entrenar un autoencoder sobre un MLP a la mitad de llama,\n",
    "solo necesitamos evaluar esa primera mitad. Además, no correremos el backward\n",
    "pass sobre los parámetros de llama, pues no buscamos modificarlos, es decir, los\n",
    "mantendrémos fijos. Por esto, tenemos que el FLOPs realizados por tal mitad del\n",
    "modelo llama es\n",
    "\n",
    "$$\n",
    "  N_l D\n",
    "$$\n",
    "\n",
    "En cuanto al SAE, solo considerando el costo de aplicar sus matrices, tenemos\n",
    "\n",
    "$$\n",
    "  6 (2d_\\text{in}d_\\text{sae})D\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de gemmascope, entre todos los SAEs que entrenaron, los más pequeños\n",
    "entrenados en las salidas de las MLPs, se entrenaron en 4 mil millones de\n",
    "vectores de activaciones, con la dimencion de los vectores en el stream\n",
    "recidual (y por lo tanto, de la salida de las capas MLP), es 2048, con\n",
    "$d_\\text{sae} = 2028 * 8$.\n",
    "\n",
    "Deseamos encontrar hiperparámetros para entrenar SAEs, para esto:\n",
    "- Usamos una primera aproximación razonable modificando los hiperparámetros para\n",
    "  los autoencoders más pequeños entrenados en salidas de las MLPs de gemma 2\n",
    "  2 B\n",
    "- Ajustamos una power law en base a 2 entrenamientos de SAEs más pequeñas,\n",
    "  usando el mismo learning rate.\n",
    "- Ajustamos una power law para el learning rate con los hiperparámetos optimos\n",
    "  que estimó el paso anterior.\n",
    "\n",
    "Si ignoramos la relación posicional de los tokens y asumimos una distribución\n",
    "uniforme, tenemos que la entropía por token es\n",
    "\n",
    "$$\n",
    "  \\log_2 (\\text{tamaño del vocabulario})\n",
    "$$\n",
    "ya que el vocabulario de gemma2 2B es 256000 y el de llama es 128000, obtenemos\n",
    "que el número de tokens equivalente sería 4.2 mil millones. Ya que nuestro\n",
    "modelo es la mitad de tamaño de gemma2 2B, una primera cantidad de datos\n",
    "razonable para entrenar nuesto sae más grande es $2.1B$\n",
    "\n",
    "En el caso de llama3.2 1B, eso resultaría en\n",
    "\n",
    "$$\n",
    "  N_l D = (2.1 \\times 10^9)(1.2 \\times 10^9) \\approx 2.5 \\times 10^{18}\n",
    "$$\n",
    "Una RTX 4090 puede realisar cada segundo un máximo de $165 \\times 10^{12}$\n",
    "operaciones con tensores de 16 bits y acumulador de 32 bits (referencia\n",
    "al reporte técnico v1.0.1), luego, estimamos 4.2 horas de entrenamiento\n",
    "tan solo considerando la computación en el modelo llama.\n",
    "\n",
    "Ahora, para estimar las horas-RTX4090 para el autoencoder, en el caso de\n",
    "entrenarlo en la salida de la MLP intermedia, tendríamos\n",
    "\n",
    "$$\n",
    "    6(2.1 \\times 10^9)(2048^2)(8)(2) = 8.5 \\times 10^{17}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import jaxtyping\n",
    "import dataclasses\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "from torch.linalg import vector_norm\n",
    "import math\n",
    "import datasets\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Step(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, threshold):\n",
    "        ctx.save_for_backward(x, threshold)\n",
    "        return (x > threshold).to(x.dtype)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        bandwidth = 0.001\n",
    "        x, threshold = ctx.saved_tensors\n",
    "\n",
    "        grad_threshold = torch.where(\n",
    "            abs(F.relu(x) - threshold) < bandwidth/2,\n",
    "            -1.0/bandwidth, 0)\n",
    "        \n",
    "        return torch.zeros_like(x), grad_threshold * grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sae(nn.Module):\n",
    "    def __init__(self, d_in, d_sae, use_pre_enc_bias=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.enc = nn.Linear(d_in, d_sae, dtype=dtype)\n",
    "        self.dec = nn.Linear(d_sae, d_in, dtype=dtype)\n",
    "        with torch.no_grad():\n",
    "            # normalize each of the d_sae dictonary vectors\n",
    "            self.dec.weight /= vector_norm(self.dec.weight, dim=0, keepdim=True)\n",
    "            self.enc.weight.copy_(self.dec.weight.clone().t())\n",
    "            self.enc.bias.copy_(torch.zeros_like(self.enc.bias))\n",
    "            self.dec.bias.copy_(torch.zeros_like(self.dec.bias))\n",
    "        self.log_threshold = nn.Parameter(\n",
    "            torch.log(torch.full((d_sae,), 0.001, dtype=dtype)))\n",
    "        self.use_pre_enc_bias = use_pre_enc_bias\n",
    "        def project_out_parallel_grad(dim, tensor):\n",
    "            @torch.no_grad\n",
    "            def hook(grad_in):\n",
    "                # norm along dim=dim of the tensor is assumed to be 1 as we\n",
    "                # are going to normalize it after every grad update\n",
    "                dot = (tensor * grad_in).sum(dim=dim, keepdim=True)\n",
    "                return grad_in - dot * tensor\n",
    "            return hook\n",
    "\n",
    "        self.dec.weight.register_hook(\n",
    "            project_out_parallel_grad(0, self.dec.weight))\n",
    "                \n",
    "\n",
    "    def forward(self,\n",
    "        x,\n",
    "        return_mask=False,\n",
    "        return_l0=True,\n",
    "        return_reconstruction_loss=True,\n",
    "    ):\n",
    "        \"We compute this much here so that compile() can do its magic\"\n",
    "        # as per train_gpt2.py on karpathy's llm.c repo, there are performance\n",
    "        # reasons not to return stuff\n",
    "        d = {}\n",
    "        original_input = x\n",
    "        if self.use_pre_enc_bias:\n",
    "            x = x - self.dec.bias\n",
    "        \n",
    "        x = self.enc(x)\n",
    "        threshold = torch.exp(self.log_threshold)\n",
    "        s = Step.apply(x, threshold)\n",
    "        if return_mask:\n",
    "            d['mask'] = s\n",
    "        if return_l0:\n",
    "            d['l0'] = s.float().mean(0).sum(-1)\n",
    "        if not return_reconstruction_loss:\n",
    "            return d\n",
    "        x = x*s\n",
    "        x = self.dec(x)\n",
    "\n",
    "        d['reconstruction'] = ((x - original_input).pow(2)).mean(0).sum()\n",
    "\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_schedule_with_warmup(\n",
    "    current_step: int,\n",
    "    warmup_steps: int,\n",
    "    total_steps: int\n",
    "    ):\n",
    "    if current_step < warmup_steps:\n",
    "        lr =  (1 + current_step) / warmup_steps\n",
    "        return lr\n",
    "    progress = (current_step - warmup_steps) / (total_steps - warmup_steps)\n",
    "    lr =  0.5 * (1 + math.cos(math.pi * progress))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity_schedule(step, warmup_steps, max_sparsity_coeff):\n",
    "    if step >= warmup_steps:\n",
    "        return max_sparsity_coeff\n",
    "    return max_sparsity_coeff*((step+1) / warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully: 668501 examples\n",
      "Features: {'activations': Sequence(feature=Value(dtype='float16', id=None), length=2048, id=None)}\n",
      "First example shape: (2048,)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset('mech-interp-uam/llama-mlp8-outputs')\n",
    "ds.set_format('numpy')\n",
    "\n",
    "# Check the dataset structure\n",
    "print(f\"Dataset loaded successfully: {len(ds['train'])} examples\")\n",
    "print(f\"Features: {ds['train'].features}\")\n",
    "print(f\"First example shape: {ds['train'][0]['activations'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ActivationsDataset(Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.data = hf_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return as float16, on modern GPUs conversion from float 16 to 32 is\n",
    "        # free compared to matmults or so I was told\n",
    "        return torch.tensor(self.data[idx]['activations'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1024\n",
    "dataset = ActivationsDataset(ds['train'])\n",
    "dataloader = DataLoader(dataset, batch_size=batch, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/653 [00:00<04:30,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=13.11782169342041\n",
      "l0=7894.46875\n",
      "sparsity_coefficient=5.0000000000000004e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 505/653 [00:25<00:07, 20.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.43382197618484497\n",
      "l0=1923.9560546875\n",
      "sparsity_coefficient=2.505e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.71it/s]\n",
      " 53%|█████▎    | 349/653 [00:17<00:15, 20.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.3316606879234314\n",
      "l0=1460.61328125\n",
      "sparsity_coefficient=5.005e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.71it/s]\n",
      " 30%|███       | 197/653 [00:10<00:22, 19.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.2898387908935547\n",
      "l0=1476.85546875\n",
      "sparsity_coefficient=7.505000000000001e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.62it/s]\n",
      "  7%|▋         | 45/653 [00:02<00:30, 19.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.2538369297981262\n",
      "l0=1487.107421875\n",
      "sparsity_coefficient=0.00010005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 546/653 [00:27<00:05, 19.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.22999128699302673\n",
      "l0=1495.8603515625\n",
      "sparsity_coefficient=0.00012505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.49it/s]\n",
      " 60%|█████▉    | 391/653 [00:20<00:14, 18.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.2109168916940689\n",
      "l0=1480.689453125\n",
      "sparsity_coefficient=0.00015005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:34<00:00, 19.00it/s]\n",
      " 36%|███▋      | 237/653 [00:12<00:20, 20.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.19227583706378937\n",
      "l0=1490.029296875\n",
      "sparsity_coefficient=0.00017505000000000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:34<00:00, 19.04it/s]\n",
      " 13%|█▎        | 85/653 [00:04<00:31, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.1758834272623062\n",
      "l0=1499.6142578125\n",
      "sparsity_coefficient=0.00020005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 584/653 [00:32<00:04, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.16457249224185944\n",
      "l0=1477.5703125\n",
      "sparsity_coefficient=0.00022505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:36<00:00, 17.83it/s]\n",
      " 66%|██████▌   | 430/653 [00:24<00:13, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.15042296051979065\n",
      "l0=1470.66015625\n",
      "sparsity_coefficient=0.00025005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:36<00:00, 17.86it/s]\n",
      " 43%|████▎     | 281/653 [00:15<00:21, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.1397533267736435\n",
      "l0=1445.5048828125\n",
      "sparsity_coefficient=0.00027505000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:35<00:00, 18.53it/s]\n",
      " 19%|█▉        | 125/653 [00:06<00:27, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.1297432780265808\n",
      "l0=1428.697265625\n",
      "sparsity_coefficient=0.00030005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 626/653 [00:34<00:01, 20.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.12482182681560516\n",
      "l0=1377.8701171875\n",
      "sparsity_coefficient=0.00032505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:36<00:00, 17.97it/s]\n",
      " 73%|███████▎  | 474/653 [00:25<00:08, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.12232045829296112\n",
      "l0=1307.60546875\n",
      "sparsity_coefficient=0.00035004999999999997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:34<00:00, 18.85it/s]\n",
      " 49%|████▉     | 322/653 [00:16<00:15, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.1226264238357544\n",
      "l0=1221.4765625\n",
      "sparsity_coefficient=0.00037505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:32<00:00, 19.80it/s]\n",
      " 26%|██▌       | 169/653 [00:08<00:23, 20.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.12564939260482788\n",
      "l0=1112.89453125\n",
      "sparsity_coefficient=0.00040005000000000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.59it/s]\n",
      "  2%|▏         | 13/653 [00:01<00:40, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.13368447124958038\n",
      "l0=989.8837890625\n",
      "sparsity_coefficient=0.00042505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 513/653 [00:26<00:06, 20.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.15467005968093872\n",
      "l0=873.8203125\n",
      "sparsity_coefficient=0.00045005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.73it/s]\n",
      " 55%|█████▌    | 362/653 [00:18<00:14, 20.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.16833460330963135\n",
      "l0=744.994140625\n",
      "sparsity_coefficient=0.00047505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:32<00:00, 19.79it/s]\n",
      " 32%|███▏      | 210/653 [00:10<00:21, 20.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.18350555002689362\n",
      "l0=657.658203125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.65it/s]\n",
      "  9%|▊         | 57/653 [00:03<00:29, 19.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.19543102383613586\n",
      "l0=583.380859375\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 554/653 [00:28<00:05, 18.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.21201559901237488\n",
      "l0=517.6044921875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.74it/s]\n",
      " 61%|██████▏   | 401/653 [00:20<00:12, 20.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.21768631041049957\n",
      "l0=472.861328125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.70it/s]\n",
      " 38%|███▊      | 250/653 [00:12<00:20, 19.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.22179633378982544\n",
      "l0=434.7255859375\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.65it/s]\n",
      " 15%|█▍        | 97/653 [00:05<00:27, 20.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.22328394651412964\n",
      "l0=401.330078125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 596/653 [00:30<00:02, 19.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.23193836212158203\n",
      "l0=368.330078125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.61it/s]\n",
      " 68%|██████▊   | 445/653 [00:22<00:10, 19.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.23430505394935608\n",
      "l0=345.4345703125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.66it/s]\n",
      " 44%|████▍     | 289/653 [00:14<00:18, 19.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.23476551473140717\n",
      "l0=327.69921875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.66it/s]\n",
      " 21%|██        | 137/653 [00:07<00:26, 19.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.2344397008419037\n",
      "l0=313.3310546875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 637/653 [00:32<00:00, 19.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24456503987312317\n",
      "l0=300.0029296875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.65it/s]\n",
      " 74%|███████▍  | 485/653 [00:24<00:08, 20.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24218963086605072\n",
      "l0=288.2880859375\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.61it/s]\n",
      " 51%|█████     | 333/653 [00:17<00:15, 20.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24388307332992554\n",
      "l0=278.9794921875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.49it/s]\n",
      " 27%|██▋       | 177/653 [00:09<00:23, 20.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24185879528522491\n",
      "l0=268.4248046875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.64it/s]\n",
      "  4%|▍         | 25/653 [00:01<00:33, 18.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.23956242203712463\n",
      "l0=264.9541015625\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 527/653 [00:26<00:06, 20.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24742871522903442\n",
      "l0=255.7783203125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.74it/s]\n",
      " 57%|█████▋    | 373/653 [00:19<00:13, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24588991701602936\n",
      "l0=248.982421875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.68it/s]\n",
      " 34%|███▍      | 221/653 [00:11<00:21, 20.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24496322870254517\n",
      "l0=246.4169921875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.69it/s]\n",
      " 10%|▉         | 65/653 [00:03<00:29, 19.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.2444174736738205\n",
      "l0=241.1533203125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 566/653 [00:28<00:04, 20.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24732226133346558\n",
      "l0=235.826171875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.45it/s]\n",
      " 63%|██████▎   | 413/653 [00:21<00:12, 19.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24833106994628906\n",
      "l0=235.2275390625\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.59it/s]\n",
      " 40%|███▉      | 261/653 [00:13<00:19, 20.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.2459370642900467\n",
      "l0=232.3447265625\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.21it/s]\n",
      " 17%|█▋        | 109/653 [00:06<00:30, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.2458069622516632\n",
      "l0=228.451171875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 609/653 [00:33<00:02, 19.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24929657578468323\n",
      "l0=224.7158203125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:35<00:00, 18.18it/s]\n",
      " 69%|██████▉   | 453/653 [00:25<00:10, 18.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.2464187741279602\n",
      "l0=223.8583984375\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:35<00:00, 18.16it/s]\n",
      " 46%|████▌     | 302/653 [00:16<00:18, 18.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.2489900141954422\n",
      "l0=224.828125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:36<00:00, 17.89it/s]\n",
      " 23%|██▎       | 149/653 [00:07<00:26, 19.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24792447686195374\n",
      "l0=222.6650390625\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 651/653 [00:33<00:00, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24904105067253113\n",
      "l0=216.8779296875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.34it/s]\n",
      " 76%|███████▌  | 497/653 [00:25<00:07, 20.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24724061787128448\n",
      "l0=217.2939453125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.60it/s]\n",
      " 52%|█████▏    | 341/653 [00:17<00:15, 19.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.2482089400291443\n",
      "l0=215.5009765625\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.75it/s]\n",
      " 29%|██▉       | 189/653 [00:09<00:23, 19.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24859726428985596\n",
      "l0=217.4033203125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.62it/s]\n",
      "  6%|▌         | 37/653 [00:02<00:31, 19.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24643957614898682\n",
      "l0=213.1767578125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 537/653 [00:27<00:05, 20.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24896806478500366\n",
      "l0=213.90234375\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.73it/s]\n",
      " 59%|█████▉    | 385/653 [00:19<00:13, 20.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24896764755249023\n",
      "l0=214.794921875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.63it/s]\n",
      " 36%|███▌      | 232/653 [00:11<00:19, 21.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24893565475940704\n",
      "l0=211.212890625\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.61it/s]\n",
      " 12%|█▏        | 77/653 [00:04<00:28, 20.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24782709777355194\n",
      "l0=211.2392578125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 577/653 [00:29<00:03, 20.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24873071908950806\n",
      "l0=211.0771484375\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.72it/s]\n",
      " 65%|██████▌   | 425/653 [00:21<00:11, 19.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24832455813884735\n",
      "l0=212.0986328125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.38it/s]\n",
      " 42%|████▏     | 273/653 [00:14<00:19, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24692755937576294\n",
      "l0=210.6708984375\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.69it/s]\n",
      " 18%|█▊        | 118/653 [00:06<00:27, 19.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24846002459526062\n",
      "l0=209.1455078125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 619/653 [00:31<00:01, 20.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24751469492912292\n",
      "l0=209.36328125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.64it/s]\n",
      " 72%|███████▏  | 467/653 [00:23<00:09, 20.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24772629141807556\n",
      "l0=211.4912109375\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:33<00:00, 19.76it/s]\n",
      " 48%|████▊     | 313/653 [00:15<00:16, 20.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24499791860580444\n",
      "l0=207.42578125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:32<00:00, 20.02it/s]\n",
      " 25%|██▍       | 161/653 [00:09<00:25, 19.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24641597270965576\n",
      "l0=205.611328125\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 653/653 [00:34<00:00, 18.97it/s]\n",
      "  0%|          | 3/653 [00:00<02:25,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reconstruction=0.24850615859031677\n",
      "l0=209.23046875\n",
      "sparsity_coefficient=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "steps = 2**16\n",
    "max_lr = 7e-5\n",
    "d_in = 2048\n",
    "d_sae = 2048*8\n",
    "model = Sae(d_in, d_sae)\n",
    "model.to('cuda')\n",
    "#model.compile()\n",
    "warmup_steps=2000\n",
    "sparcity_warmup_steps=10000\n",
    "total_steps=32000 #for now\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.enc.parameters(), \"lr\":max_lr, \"betas\":(0.0,0.999)},\n",
    "    {\"params\": model.dec.parameters(), \"lr\":max_lr, \"betas\":(0.0,0.999)},\n",
    "    {\"params\": model.log_threshold, \"lr\":3.5*max_lr, \"betas\":(0.9,0.999)},\n",
    "])\n",
    "max_sparsity_coeff = 0.0005\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda step: cosine_schedule_with_warmup(step, warmup_steps, total_steps)\n",
    ")\n",
    "# train_ds = fake_train_loader(batch, d_in, total_steps)\n",
    "total_step = 0\n",
    "should_break = False\n",
    "for epoch in range(1000):\n",
    "    for step, x in enumerate(tqdm(dataloader)):\n",
    "        x /= 3.4 # this is supposed to be the expected norm\n",
    "        x = x.to(dtype).to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "        d = model(x)\n",
    "        reconstruction_loss, l0 = d['reconstruction'], d['l0']\n",
    "        sparsity_coefficient = sparsity_schedule(total_step, sparcity_warmup_steps, max_sparsity_coeff)\n",
    "        loss = reconstruction_loss + sparsity_coefficient * l0\n",
    "        # log losses, compute stats, etc\n",
    "        grad = loss.backward()\n",
    "        # norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # metrics\n",
    "        if (total_step % 500) == 0:\n",
    "            with torch.no_grad():\n",
    "                # print metrics\n",
    "                print(f\"reconstruction={reconstruction_loss.item()}\")\n",
    "                print(f\"l0={l0.item()}\")\n",
    "                # print(f\"norm={norm.item()}\")\n",
    "                print(f\"{sparsity_coefficient=}\")\n",
    "        optimizer.step()\n",
    "        # TODO: sparsity_coefficient scheduler\n",
    "        # print(scheduler.get_lr())\n",
    "        scheduler.step()\n",
    "\n",
    "        # normalize\n",
    "        with torch.no_grad():\n",
    "            wdecnorm = vector_norm(model.dec.weight, dim=0, keepdim=True)\n",
    "            model.dec.weight /= wdecnorm\n",
    "    # print(f\"epoch loss: {loss.detach().item()}\")\n",
    "        total_step +=1\n",
    "        if total_step > total_steps:\n",
    "            should_break = True\n",
    "            break\n",
    "    if should_break:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/workspace/llama3.2-1b-sae/sae.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
